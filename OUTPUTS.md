# Project Outputs Guide

This document describes all the outputs generated by each step of the workflow.

## Step 0: Data Preparation

### Outputs
- `training_images/` - Folder containing 5,000 training images (500 per class)
  - `training_images/airplane/airplane_000.png` to `airplane_499.png`
  - `training_images/automobile/automobile_000.png` to `automobile_499.png`
  - ... (10 classes total)

- `test_images/` - Folder containing 1,000 test images (100 per class)
  - `test_images/airplane/airplane_000.png` to `airplane_099.png`
  - `test_images/automobile/automobile_000.png` to `automobile_099.png`
  - ... (10 classes total)

- `selected_indices.json` - Metadata about dataset selection
  ```json
  {
    "train_per_class": 500,
    "test_per_class": 100,
    "select_mode": "first",
    "random_seed": 42
  }
  ```

---

## Step 1: Training

### Console Output
```
Device: mps
Loading training data...
Training samples: 5000
Classes: ['airplane', 'automobile', 'bird', ...]

Architecture: original
Kernel size: 3
Total parameters: 128,806,154

Starting training for 40 epochs...
============================================================
Epoch   1/40 | Loss: 1.8234 | Train Acc: 0.3456
Epoch   2/40 | Loss: 1.6123 | Train Acc: 0.4123
...
Epoch  40/40 | Loss: 0.2134 | Train Acc: 0.9234
============================================================

Training complete!
Best training accuracy: 0.9234
Model saved to: outputs/vgg_original_k3.pt
Metadata saved to: outputs/vgg_original_k3_meta.txt
```

### File Outputs
- **`outputs/vgg_{depth}_k{kernel}.pt`** - Model checkpoint (PyTorch state_dict)
  - Example: `outputs/vgg_original_k3.pt` (107 MB)

- **`outputs/vgg_{depth}_k{kernel}_meta.txt`** - Training metadata
  ```
  Architecture: original
  Kernel size: 3
  Conv layers: 8
  Total parameters: 128,806,154
  Epochs trained: 40
  Learning rate: 0.01
  Batch size: 64
  Best training accuracy: 0.9234
  ```

---

## Step 2: Testing

### Console Output
```
Device: mps
Loading test data...
Test samples: 1000
Classes: ['airplane', 'automobile', 'bird', ...]

Loading model from: outputs/vgg_original_k3.pt
Architecture: original
Kernel size: 3
Total parameters: 128,806,154

Evaluating on test set...

Test Accuracy: 0.7850

Classification Report:
============================================================
              precision    recall  f1-score   support

    airplane     0.8200    0.8200    0.8200       100
  automobile     0.8800    0.8800    0.8800       100
        bird     0.6900    0.6900    0.6900       100
         cat     0.6300    0.6300    0.6300       100
        deer     0.7600    0.7600    0.7600       100
         dog     0.7400    0.7400    0.7400       100
        frog     0.8600    0.8600    0.8600       100
       horse     0.8400    0.8400    0.8400       100
        ship     0.8700    0.8700    0.8700       100
       truck     0.7600    0.7600    0.7600       100

    accuracy                         0.7850      1000
   macro avg     0.7850    0.7850    0.7850      1000
weighted avg     0.7850    0.7850    0.7850      1000

Classification report saved to: outputs/classification_report_original_k3.txt
Confusion matrix saved to: outputs/confusion_matrix_original_k3.png

============================================================
Evaluation complete!
============================================================
```

### File Outputs
- **`outputs/classification_report_{depth}_k{kernel}.txt`** - Detailed metrics
  - Contains accuracy, precision, recall, F1-score for each class

- **`outputs/confusion_matrix_{depth}_k{kernel}.png`** - Confusion matrix visualization
  - Heat map showing true vs predicted labels
  - Annotated with counts
  - Color-coded (darker = more predictions)

---

## Step 3: Adversarial Attack

### Console Output
```
Device: mps
Random seed: Not set (results will vary each run)

Loading test data...
Test samples: 1000
Classes: ['airplane', 'automobile', 'bird', ...]
Shuffle: False (different examples each run: True)

Loading model from: outputs/vgg_original_k3.pt
Architecture: original
Kernel size: 3
Total parameters: 128,806,154

============================================================
FGSM ADVERSARIAL ATTACK
============================================================
Testing with epsilon values: [0.0, 0.01, 0.03, 0.05, 0.1]

Running FGSM attack with ε = 0.000... Accuracy: 0.7850
Running FGSM attack with ε = 0.010... Accuracy: 0.6730
Running FGSM attack with ε = 0.030... Accuracy: 0.4120
Running FGSM attack with ε = 0.050... Accuracy: 0.2560
Running FGSM attack with ε = 0.100... Accuracy: 0.0980

Results saved to: outputs/attack_results_original_k3.txt
Adversarial curve saved to: outputs/fgsm_curve_original_k3.png
Attack examples (ε=0.030) saved to: outputs/attack_examples_original_k3_eps0.030.png
Attack examples (ε=0.050) saved to: outputs/attack_examples_original_k3_eps0.050.png
Attack examples (ε=0.100) saved to: outputs/attack_examples_original_k3_eps0.100.png

============================================================
ATTACK SUMMARY
============================================================
Clean accuracy (ε=0.00):  0.7850
Worst accuracy (ε=0.10): 0.0980
Accuracy drop:             0.6870
============================================================
```

### File Outputs
- **`outputs/attack_results_{depth}_k{kernel}.txt`** - Attack summary table
  ```
  FGSM Adversarial Attack Results
  ============================================================
  Model: original VGG (k=3)
  Model path: outputs/vgg_original_k3.pt

  Epsilon	Accuracy	Accuracy Drop
  ------------------------------------------------------------
  0.000	0.7850		0.0000
  0.010	0.6730		0.1120
  0.030	0.4120		0.3730
  0.050	0.2560		0.5290
  0.100	0.0980		0.6870
  ```

- **`outputs/fgsm_curve_{depth}_k{kernel}.png`** - Robustness curve
  - Line plot showing accuracy vs epsilon
  - Annotated with accuracy values
  - Shows how model degrades under attack

- **`outputs/attack_examples_{depth}_k{kernel}_eps{value}.png`** - Visual examples (3 files)
  - Shows original image, perturbation (×10 amplified), and adversarial image
  - Up to 5 example images per epsilon value
  - Labels show: true label, original prediction, adversarial prediction
  - Success indicator (✓ = attack succeeded, ✗ = failed)

---

## Summary Table

| Step | Console Output | File Outputs |
|------|---------------|--------------|
| **Step 0** | Download progress, image counts | `training_images/`, `test_images/`, `selected_indices.json` |
| **Step 1** | Training progress, accuracy per epoch | `vgg_*.pt`, `vgg_*_meta.txt` |
| **Step 2** | Test accuracy, classification report | `classification_report_*.txt`, `confusion_matrix_*.png` |
| **Step 3** | Attack accuracy per epsilon, summary | `attack_results_*.txt`, `fgsm_curve_*.png`, `attack_examples_*.png` |

---

## Output File Naming Convention

All outputs use this naming pattern:
```
{prefix}_{depth}_k{kernel}.{extension}
```

Examples:
- `vgg_original_k3.pt` - Original VGG with kernel size 3
- `vgg_shallow_k5.pt` - Shallow VGG with kernel size 5
- `vgg_deep_k7.pt` - Deep VGG with kernel size 7
- `confusion_matrix_original_k3.png`
- `attack_results_deep_k5.txt`

---

## Viewing Results

### Text Files
```bash
# View training metadata
cat outputs/vgg_original_k3_meta.txt

# View classification report
cat outputs/classification_report_original_k3.txt

# View attack results
cat outputs/attack_results_original_k3.txt
```

### Images
```bash
# Open confusion matrix
open outputs/confusion_matrix_original_k3.png

# Open adversarial robustness curve
open outputs/fgsm_curve_original_k3.png

# Open adversarial examples
open outputs/attack_examples_original_k3_eps0.050.png
```

---

## Expected Output Sizes

| File Type | Approximate Size |
|-----------|-----------------|
| Model checkpoint (`.pt`) | 100-150 MB |
| Metadata (`.txt`) | < 1 KB |
| Classification report (`.txt`) | 1-2 KB |
| Confusion matrix (`.png`) | 100-200 KB |
| FGSM curve (`.png`) | 50-100 KB |
| Attack examples (`.png`) | 200-500 KB |
| Attack results (`.txt`) | < 1 KB |

**Total disk space needed**: ~500 MB (including dataset, models, and all outputs)
